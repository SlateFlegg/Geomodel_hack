# Геомодель 25 | Хакатон | Задача 2    
**Задача**
Для решения задач геофизики, включая сейсморазведку и микросейсмический мониторинг, требуется эффективное моделирование волновых сейсмических откликов. Полноволновое численное моделирование (вязкоупругая постановка) обеспечивает более реалистичное представление этих откликов, однако, требует значительных вычислительных ресурсов, особенно при получении высокочастотных компонент в откликах.     
**Цель**  
Разработать ML-модель, способную восстанавливать недостающую высокочастотную составляющую в сейсмических откликах, полученных в ходе численного моделирования с ограниченной выборкой полночастотных откликов. Предполагается, что нейросеть, обученная на откликах обедненных высокими частотами и откликах с наличием высоких частот от одного сейсмического источника, сможет синтезировать высокочастотные компоненты для соседних источников, тем самым оптимизируя процесс полноволнового численного моделирования.  
**Метрика**  
МАЕ по всеей площади временного пространства  

Тетрадка с финальной моделью [github](https://github.com/SlateFlegg/Geomodel_hack/blob/main/FTH_final_notebook.ipynb)    
Тетрадка с подбором архитектуры [github](https://github.com/SlateFlegg/Geomodel_hack/blob/main/FasterThanHammer.ipynb)    
Тетрадка с анализом данных [github](https://github.com/SlateFlegg/Geomodel_hack/blob/main/Analisys.ipynb)  


# Summary  
В результате экспериментов была выбрана модель `CoordsModUnet` домонтрировшая хороший результат как по метрике, так и по визуальному контролю    
![image](https://github.com/user-attachments/assets/52805749-8d21-4a50-b316-084693657eea)

**Общие замечания**:    
Подходить к решению задачи можно несколькими способами, классическим - через свёртки и вариации CNN, как к задачи апскейлинга, с добавлением расстояния и/или положения сенсора. В основном, в таких случаях применяются Unet-подобные модели, с нескольмими этапами свёртки и skip-connections.  
* Всего 2016 сенсоров, однако для каждого сенсора есть 6 тензоров, а также 3 канала  
* Главная метрика MAE для всего спектра во временной области, поэтому ориентироватся на отдельные частоты не обязательно. Более того, из аналитической тетрадки видно, что наибольшую раницу между 9м и 14м-моделированием задают частоты: от 0 до 20 и от 20 до 40. А также стоит помнить, что МАЕ неусточива к фазе, неустойчика к сдвигу, а работа во временном пространстве не выловит разницу в частотном составе      
* Важно вносить положение сенсоров - иначе модель может искать не "приближенные" к каждому сенсору данные, а нечто среднее между всеми показателями сенсоров при этом теряя физический смысл сейсмики.  
* Сами по себе данные достаточно схожи, нужно защищаться от переобучения шумом, dropout'ами или skip-connections чтобы не потерять значимую физическую информацию   
* Увеличение количество сенсоров ведёт к необратимому росту ошибки. Возможно, обучение секторами может дать дополнительное качество (но в данном решении не реализовано)

**Рассмотренные модели**    
*Для отбора моделей параметры: `selected_sensors_num`=2016, `batch_size`=32, `epochs`=30*   
1) `Dummy`: `0.045832` Примерная оценка МАЕ в случае если бы мы просто использовали 14м-данные. Эта оценка нужна, чтобы иметь представление о качесве работы моделей, она позволяет оценить качество сверху. Очевидно, что тоже мы будем наблюдать и при преобразование Фурье "посередине"    
2) `Baseline model` - она представляет собой классическую Unet модель, в которой не учитываются расстояние и положение сенсоров. Бейзлайн на всех сенсорах и 300 эпохах показывает хороший результат: `0.022763`. Почти в двое лучше `dummy`. Для первичного отбора моделей также посмотрим на обучение на 30 эпохах и для 2016 сенсорах - `0.024654`      
На графике Loss-epochs сразу видна характерная черта Unet-подбных моделей - существенные скачки как train, так и validation loss, которые в том числе могут так себя вести из-за разных пород.
![image](https://github.com/user-attachments/assets/3ac9b7a1-f68e-4f31-98b1-b4178d5729f8)

**Эксперименты с моделями**  
1) `FTHUnet` - создаём новый класс данных, который будет включать в себя расстояния. Сначала проверим, как вообще включение расстояний влияет на метрики. Для быстрой провекри выберём только 1000 сенсоров и небольшое количество эпох. В данной модели расстояния учитываются с помощью двух линейных слоёв и функцией активации `ReLu`. Метрика: `0.024821`. В целом, происходит ожидаемое падение метрики, однако не сильно - вероятно это правильный путь.
2) Развивая эту идею пишем простую модель, без skip-connections, но с большей устойчивостью к переобучению: `SimpleModel`, задача понять нужно ли отходить от идеи со skip-connections, возможно они могут привносить слишком много артефактов из 14м-модели: MAE: `0.027044`     
3) `CNN_LSTM` Отдельной идей посмотреть на эти данные как time-series. В частности включить `LSTM` подходы. А также "обрезку" по определённому значению частоты, чтобы учесть только "информативные участки". Это самая вычислительносложная модель. `0.027984` 
4) `GNN` - модель свёртки на графах. Результат на отборе: `0.024495`.Это можель считает сразу все каналы и тензоры, возможность настройки гиперпарамтера радиуса учёта датчиков. В модели два модуля: свертка на графах, которая распространяет признаки узлов через структуру графа и distance-processing.   
Может выглядеть, что distance-processing избыточен (ведь в графе уже учтены расстояния между сенсорами), однако задача этой части преобразовывать расстояния в "веся влияния".   
5) `ModUnet` - модификация Unet с большим числом блоков кодирования-декодирования, skip-connections и, что самое важное, с увеличенными свёртками (kernel_size=7). Результат на отборе: `0.019860`. Это модель вдохновлена работой: [github:SeismicPro](https://github.com/learnserd/SeismicPro/blob/master/tutorials/4.Models.ipynb)    
6) `CoordModNet` - главное отличие от предыдущей сетки это включение учёт координат, а не только расстояний.


